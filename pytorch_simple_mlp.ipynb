{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy \n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_ = 1\n",
    "\n",
    "def dump_info(tensor_,title):\n",
    "    if dump_ == 1:\n",
    "        print(title)\n",
    "        print( list(tensor_.size() ))\n",
    "        print(tensor_)\n",
    "        \n",
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            print(\"Feedforward input_size \",input_size,\" hidden_size \", hidden_size)\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()        \n",
    "        \n",
    "        def forward(self, x):\n",
    "            global dump_\n",
    "            \n",
    "            dump_info(x,\"input\")\n",
    "            \n",
    "            hidden = self.fc1(x)            \n",
    "            dump_info(hidden,\"hidden fc1\")\n",
    "            \n",
    "            relu = self.relu(hidden)            \n",
    "            dump_info(relu,\"relu\")\n",
    "            \n",
    "            output = self.fc2(relu)            \n",
    "            dump_info(output,\"output fc2\")\n",
    "            \n",
    "            sigmoid_output = self.sigmoid(output)\n",
    "            dump_info(sigmoid_output,\"sigmoid_output\")\n",
    "            #close logging\n",
    "            dump_ = 2\n",
    "            \n",
    "            return sigmoid_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE RANDOM DATA POINTS\n",
    "total_samples = 5\n",
    "x_train, y_train = make_classification(n_samples=total_samples,n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "x_test, y_test = make_classification(n_samples=total_samples,n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedforward input_size  2  hidden_size  4\n",
      "Feedforward(\n",
      "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Feedforward(2, 4)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "[5, 2]\n",
      "tensor([[-0.8300,  0.3065],\n",
      "        [-1.0359, -0.9094],\n",
      "        [-1.0609, -0.3498],\n",
      "        [ 1.5576,  1.2509],\n",
      "        [ 1.5136,  0.0725]])\n",
      "hidden fc1\n",
      "[5, 4]\n",
      "tensor([[ 0.7310,  1.0147,  0.2710, -0.2432],\n",
      "        [ 0.0648,  0.6299, -0.2630,  0.4065],\n",
      "        [ 0.3659,  0.8893,  0.0429,  0.1143],\n",
      "        [ 1.3517, -0.2168, -0.4325, -0.8751],\n",
      "        [ 0.7132, -0.6967, -1.0281, -0.2543]], grad_fn=<AddmmBackward>)\n",
      "relu\n",
      "[5, 4]\n",
      "tensor([[0.7310, 1.0147, 0.2710, 0.0000],\n",
      "        [0.0648, 0.6299, 0.0000, 0.4065],\n",
      "        [0.3659, 0.8893, 0.0429, 0.1143],\n",
      "        [1.3517, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7132, 0.0000, 0.0000, 0.0000]], grad_fn=<ThresholdBackward0>)\n",
      "output fc2\n",
      "[5, 1]\n",
      "tensor([[-0.0360],\n",
      "        [-0.0506],\n",
      "        [-0.0020],\n",
      "        [-0.0686],\n",
      "        [-0.1138]], grad_fn=<AddmmBackward>)\n",
      "sigmoid_output\n",
      "[5, 1]\n",
      "tensor([[0.4910],\n",
      "        [0.4874],\n",
      "        [0.4995],\n",
      "        [0.4829],\n",
      "        [0.4716]], grad_fn=<SigmoidBackward>)\n",
      "Test loss before training 0.7030660510063171\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "before_train = criterion(y_pred.squeeze(), y_test)\n",
    "print('Test loss before training' , before_train.item())\n",
    "\n",
    "#input      [5, 2]  our input shape\n",
    "#hidden fc1 [5, 4]  (fc1): Linear(in_features=2, out_features=4, bias=True) \n",
    "#relu       [5, 4]  relu same size\n",
    "#output fc2 [5, 1]  Linear(in_features=4, out_features=1, bias=True)\n",
    "#sigmoid_output  [5, 1]  Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.6781232953071594\n",
      "Epoch 1: train loss: 0.6776665449142456\n",
      "Epoch 2: train loss: 0.6772103309631348\n",
      "Epoch 3: train loss: 0.6767548322677612\n",
      "Epoch 4: train loss: 0.6762996912002563\n",
      "Epoch 5: train loss: 0.6758453845977783\n",
      "Epoch 6: train loss: 0.675391674041748\n",
      "Epoch 7: train loss: 0.674938440322876\n",
      "Epoch 8: train loss: 0.6744857430458069\n",
      "Epoch 9: train loss: 0.6740336418151855\n",
      "Epoch 10: train loss: 0.6735818982124329\n",
      "Epoch 11: train loss: 0.6731308698654175\n",
      "Epoch 12: train loss: 0.6726801991462708\n",
      "Epoch 13: train loss: 0.672230064868927\n",
      "Epoch 14: train loss: 0.6717803478240967\n",
      "Epoch 15: train loss: 0.6713311672210693\n",
      "Epoch 16: train loss: 0.6708823442459106\n",
      "Epoch 17: train loss: 0.6704340577125549\n",
      "Epoch 18: train loss: 0.6699860692024231\n",
      "Epoch 19: train loss: 0.6695384979248047\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 20\n",
    "for epoch in range(epoch):    \n",
    "    optimizer.zero_grad()    \n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)    \n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), y_train)\n",
    "   \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after Training 0.69452965259552\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "after_train = criterion(y_pred.squeeze(), y_test) \n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
