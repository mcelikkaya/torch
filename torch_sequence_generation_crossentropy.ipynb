{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_sequence_generation_crossentropy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "goxkU5ztfF9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "768a546b-24e2-4aed-bdd3-9b4bb18bb4e3"
      },
      "source": [
        "\"\"\"\n",
        "In this notebook , I try m -> n sequence generation with crossentropy.\n",
        "Just changed the architecture:\n",
        "Change the loss function\n",
        "and Logsoftmax is not applied for last layer.\n",
        "\n",
        "my alphabet has 5 letters \"abcde\"\n",
        "I create a sequence of 6 letters and output most occuring 2 letters.\n",
        "\n",
        "input  = ['a', 'b', 'a', 'd', 'b', 'a']\n",
        "output = ['a', 'b']\n",
        "\n",
        "1st is most occuring letter\n",
        "2ns is second most occuring.\n",
        "In eval method  i both measure, any match of sequence\n",
        "and full match of sequence.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "from io import open\n",
        "import os, string, random, time, math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7e2e6e0d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73PRdjE8fHgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#My utility to log intermediate steps\n",
        "class StepLogger():\n",
        "    def __init__(self,capacity):\n",
        "        self.tensor_datas = {}        \n",
        "        self.capacity = capacity\n",
        "        self.added_labels = []\n",
        "        \n",
        "    \n",
        "    def add_info(self,tensor_data,tensor_label):\n",
        "        if tensor_label not in self.added_labels:\n",
        "            self.added_labels.append( tensor_label )\n",
        "        \n",
        "        if tensor_label in self.tensor_datas.keys():\n",
        "            current_arr = self.tensor_datas.get(tensor_label)\n",
        "            if len(current_arr) < self.capacity:\n",
        "                current_arr = self.tensor_datas.get(tensor_label, [])\n",
        "                current_arr.append(tensor_data)\n",
        "        else:\n",
        "            self.tensor_datas[tensor_label] = [tensor_data]\n",
        "    \n",
        "    def get_default_summary(self,show_data=False,summary_count=1):\n",
        "        self.get_summary(self.added_labels,show_data)\n",
        "        \n",
        "    def get_summary(self,labels,show_data=False,summary_count=1):\n",
        "        count = 0\n",
        "        for i in range(summary_count):\n",
        "            for l in labels:\n",
        "                label_data = self.tensor_datas.get(l)[count]\n",
        "                print(l)\n",
        "                if torch.is_tensor(label_data):\n",
        "                    print( list(label_data.size() ) )\n",
        "                if not show_data and not torch.is_tensor(label_data):\n",
        "                    print(label_data)\n",
        "                if show_data:    \n",
        "                    print(label_data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJoHHM-3fKUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b63d9236-1092-40e4-c0c8-b67e2168c825"
      },
      "source": [
        "#data generation methods\n",
        "all_letters = \"abcde\"\n",
        "\n",
        "\n",
        "def prepare_sequence(name):\n",
        "    rep = np.zeros( (len(name), 1) )\n",
        "    for index, letter in enumerate(name):\n",
        "        pos = all_letters.find(letter)\n",
        "        rep[index][0] = pos\n",
        "    return rep\n",
        "\n",
        "def gen_1_tuple():\n",
        "    seq_len = 3\n",
        "    template = [1,1,2,2,3,3,4,4,5,5]\n",
        "    sequence = random.sample(template,3)\n",
        "    b = {}\n",
        "    for item in sequence:\n",
        "        #only count smaller than 10\n",
        "        if item < 10:\n",
        "            b[item] = b.get(item, 0) + 1    \n",
        "    sb = sorted(b.items(), key=lambda x: x[1],reverse=True)   \n",
        "    most_occur = 1\n",
        "    most_occur_2 = 1\n",
        "    try:\n",
        "        most_occur   = sb[0][0]\n",
        "        \n",
        "        most_occur_2 = sb[1][0]\n",
        "    except Exception as ex:\n",
        "        print(\"sb \",b)\n",
        "        most_occur = 1\n",
        "        \n",
        "            \n",
        "    result_list = sequence+[most_occur,most_occur,most_occur_2] \n",
        "    result_list = random.sample(result_list,len(result_list))\n",
        "    to_word = [all_letters[i-1] for i in result_list ]\n",
        "    return to_word,[all_letters[most_occur-1],all_letters[most_occur_2-1] ]\n",
        "\n",
        "def nat_rep(data_index):\n",
        "    return np.array([all_letters.index(i)for i in data_index])\n",
        "\n",
        "def gen_data_tuple():\n",
        "    d1 = gen_1_tuple()\n",
        "    return d1    \n",
        "    \n",
        "d = gen_data_tuple()\n",
        "print(d)\n",
        "nat_rep(d[1])\n",
        "#seq_rep(d[0])\n",
        "db = gen_data_tuple()\n",
        "print(db)\n",
        "print(len(db[0]))\n",
        "print(nat_rep(db[1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['a', 'a', 'b', 'd', 'b', 'b'], ['b', 'a'])\n",
            "(['e', 'c', 'b', 'e', 'e', 'c'], ['e', 'c'])\n",
            "6\n",
            "[4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHs582bjfaA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trains = [ gen_data_tuple() for _ in range(2000)]\n",
        "X_train = [t[0] for t in trains ]\n",
        "y_train = [t[1] for t in trains ]\n",
        "\n",
        "tests = [ gen_data_tuple() for _ in range(200)]\n",
        "X_test = [t[0] for t in tests ]\n",
        "y_test = [t[1] for t in tests ]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EE1fJbpffnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7086fd07-430c-4cda-da47-a23d629953cb"
      },
      "source": [
        "print(\"data \" ,\" \".join(X_train[0]) )\n",
        "print(\"label \" ,y_train[0] )\n",
        "\n",
        "print(\"data \" ,prepare_sequence(X_train[0]) )\n",
        "print(\"label \" ,prepare_sequence(y_train[0]) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  e c b c c b\n",
            "label  ['c', 'b']\n",
            "data  [[4.]\n",
            " [2.]\n",
            " [1.]\n",
            " [2.]\n",
            " [2.]\n",
            " [1.]]\n",
            "label  [[2.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuzPdB6Tfi4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7454c5a0-e3ad-4fa5-b046-b21d1de2beb2"
      },
      "source": [
        "#check distribution of data\n",
        "count = {}\n",
        "for l in all_letters:\n",
        "    count[l] = 0\n",
        "\n",
        "for d in trains:\n",
        "    count[d[1][0]] += 1\n",
        "    count[d[1][1]] += 1\n",
        "\n",
        "#plot the distribution\n",
        "plt.style.use(\"seaborn\")\n",
        "plt_ = sns.barplot(list(count.keys()), list(count.values()))\n",
        "plt_.set_xticklabels(plt_.get_xticklabels(), rotation = 90)\n",
        "plt.show()   "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFGCAYAAAC7euwcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZrElEQVR4nO3dcXDTd/3H8VfaNBcLwTZdgisbEwbCzpZ2tSpU6uwKmrJ5K44WrlI8rJy7FYauSrFy2DndjbGhgL0xxyj94Q/pkQ1XPaSVney8s3Q/zKzFw1O43W4ia7+ZLQXaDij5/fMzP5TRFEjIh/T5+It88s0373xud899vxmZLRQKhQQAAOIqKd4DAAAAggwAgBEIMgAABiDIAAAYgCADAGAAggwAgAHs8XxzyzoTz7cHAOCm8nhcV32OK2QAAAxAkAEAMABBBgDAAAQZAAADEGQAAAxAkAEAMABBBgDAAAQZAAADEGQAAAxAkAEAMABBBgDAAAQZAAADEGQAAAwQ1//bEwBE04s/PhDvEYy14hu+eI+ACCIG+dy5c6qtrdXp06d14cIFVVdXy+PxqL6+XpI0Y8YMPfHEE5Kk7du368CBA7LZbFq5cqXuu+++mA4PAECiiBjkffv2acqUKaqpqVF3d7e+8pWvyOPxqK6uTrNmzVJNTY1ef/11TZ06Vfv379eePXt09uxZVVRUaO7cuUpOTr4ZnwMAgFtaxO+Q09PT1dfXJ0nq7+9XWlqaTp48qVmzZkmSioqK1N7ero6ODhUWFsrhcMjtdmvSpEk6fvx4bKcHACBBRLxCfuCBB/TKK69o/vz56u/v1/PPP6/vf//74eczMjJkWZbS0tLkdrvD6263W5ZlacaMGbGZHLjF/E/NY/EewViffG5LvEcA4i5ikF999VVlZmbqpZde0l/+8hdVV1fL5XKFnw+FQh/4uqutXy49PVV2+8i3tCvW/HfE84xVu5/5crxHAKLC43FFPgg3hD02X8QgBwIBzZ07V5I0c+ZMvf/++7p48WL4+e7ubnm9Xnm9Xr311ltXrI+kt3fgeueGJMs6E+8RgKjgn+XYi9YeH+t4LirnSVT3fLpmxOdH+hejiN8h33XXXers7JQknTx5UuPGjdPdd9+tI0eOSJLa2tpUWFio2bNn69ChQzp//ry6u7vV09OjadOmXcvnAABgzIp4hbx48WLV1dVp6dKlunjxourr6+XxeLR+/XpdunRJOTk5KigokCSVl5dr6dKlstlsqq+vV1ISvztyK/j2r9bFewSjbXzwB/EeAcAYEDHI48aN0+bNm69Y37179xVrlZWVqqysjM5kAACMIVzCAgBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIAB7JEO2Lt3r1paWsKPjx49qp///Oeqr6+XJM2YMUNPPPGEJGn79u06cOCAbDabVq5cqfvuuy82UwMAkGAiBrmsrExlZWWSpDfeeEO//vWv9cMf/lB1dXWaNWuWampq9Prrr2vq1Knav3+/9uzZo7Nnz6qiokJz585VcnJyzD8EAAC3umu6Zd3Q0KAVK1bo5MmTmjVrliSpqKhI7e3t6ujoUGFhoRwOh9xutyZNmqTjx4/HZGgAABLNqIP8pz/9SbfffruSk5M1YcKE8HpGRoYsy1IwGJTb7Q6vu91uWZYV3WkBAEhQEW9Z/4vf79fChQuvWA+FQh94/NXWL5eeniq7nVva18vjccV7hDGBfY499jj2orXHx6JylsR1I/s86iB3dHRo3bp1stls6uvrC693d3fL6/XK6/XqrbfeumJ9JL29A9cxMv7Fss7Ee4QxgX2OPfY49tjjmyPSPo8U7FHdsu7u7ta4cePkcDiUkpKiqVOn6siRI5KktrY2FRYWavbs2Tp06JDOnz+v7u5u9fT0aNq0adfwMQAAGLtGdYVsWda/fT9cV1en9evX69KlS8rJyVFBQYEkqby8XEuXLpXNZlN9fb2SkvhrzgAAjMaogpyVlaXt27eHH0+bNk27d+++4rjKykpVVlZGbzoAAMYILmEBADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAD20RzU0tKi7du3y26367HHHtOMGTO0Zs0aDQ8Py+PxaOPGjXI4HGppaVFTU5OSkpJUXl6usrKyWM8PAEBCiBjk3t5eNTQ06OWXX9bAwIC2bt2q1tZWVVRUqKSkRJs2bZLf71dpaakaGhrk9/uVkpKiRYsWaf78+UpLS7sZnwMAgFtaxFvW7e3tmjNnjsaPHy+v16snn3xSHR0dKi4uliQVFRWpvb1dnZ2dys7OlsvlktPpVF5engKBQMw/AAAAiSDiFfLf//53DQ0N6ZFHHlF/f79WrVqlwcFBORwOSVJGRoYsy1IwGJTb7Q6/zu12y7Ks2E0OAEACGdV3yH19ffrJT36if/zjH1q2bJlCoVD4ucv/fLmrrV8uPT1VdnvyKEfFf/J4XPEeYUxgn2OPPY69aO3xsaicJXHdyD5HDHJGRobuvfde2e12TZ48WePGjVNycrKGhobkdDrV3d0tr9crr9erYDAYfl1PT49yc3NHPHdv78B1Dw7Jss7Ee4QxgX2OPfY49tjjmyPSPo8U7IjfIc+dO1eHDx/WpUuX1Nvbq4GBARUUFKi1tVWS1NbWpsLCQuXk5Kirq0v9/f06d+6cAoGA8vPzr/GjAAAwNkW8Qp44caK+8IUvqLy8XJK0bt06ZWdnq7a2Vs3NzcrMzFRpaalSUlJUU1Ojqqoq2Ww2VVdXy+XiNhQAAKMxqu+QlyxZoiVLlvzbWmNj4xXH+Xw++Xy+6EwGAMAYwi91AQBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIAB7JEO6Ojo0OrVqzV9+nRJ0sc+9jF97Wtf05o1azQ8PCyPx6ONGzfK4XCopaVFTU1NSkpKUnl5ucrKymL+AQAASAQRgyxJn/rUp7Rly5bw4+985zuqqKhQSUmJNm3aJL/fr9LSUjU0NMjv9yslJUWLFi3S/PnzlZaWFrPhAQBIFNd1y7qjo0PFxcWSpKKiIrW3t6uzs1PZ2dlyuVxyOp3Ky8tTIBCI6rAAACSqUV0hHz9+XI888ohOnz6tlStXanBwUA6HQ5KUkZEhy7IUDAbldrvDr3G73bIsKzZTAwCQYCIG+aMf/ahWrlypkpISvfPOO1q2bJmGh4fDz4dCoQ983dXWL5eeniq7PfkaxsXlPB5XvEcYE9jn2GOPYy9ae3wsKmdJXDeyzxGDPHHiRC1YsECSNHnyZN12223q6urS0NCQnE6nuru75fV65fV6FQwGw6/r6elRbm7uiOfu7R247sEhWdaZeI8wJrDPsccexx57fHNE2ueRgh3xO+SWlha99NJL//dGlt577z196UtfUmtrqySpra1NhYWFysnJUVdXl/r7+3Xu3DkFAgHl5+dfy+cAAGDMiniFfP/99+tb3/qWXnvtNV24cEH19fW65557VFtbq+bmZmVmZqq0tFQpKSmqqalRVVWVbDabqqur5XJxGwoAgNGIGOTx48dr27ZtV6w3NjZesebz+eTz+aIzGQAAYwi/1AUAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABiDIAAAYgCADAGAAggwAgAEIMgAABhhVkIeGhjRv3jy98sorOnXqlCorK1VRUaHVq1fr/PnzkqSWlhY9/PDDKisr0969e2M6NAAAiWZUQX7++ef14Q9/WJK0ZcsWVVRUaPfu3brrrrvk9/s1MDCghoYG7dy5U7t27VJTU5P6+vpiOjgAAIkkYpBPnDih48eP63Of+5wkqaOjQ8XFxZKkoqIitbe3q7OzU9nZ2XK5XHI6ncrLy1MgEIjp4AAAJJKIQd6wYYPWrl0bfjw4OCiHwyFJysjIkGVZCgaDcrvd4WPcbrcsy4rBuAAAJCb7SE/+4he/UG5uru68884PfD4UCl3T+n9KT0+V3Z48qmNxJY/HFe8RxgT2OfbY49iL1h4fi8pZEteN7POIQT506JDeeecdHTp0SO+++64cDodSU1M1NDQkp9Op7u5ueb1eeb1eBYPB8Ot6enqUm5sb8c17eweue3BIlnUm3iOMCexz7LHHscce3xyR9nmkYI8Y5B//+MfhP2/dulWTJk3Sm2++qdbWVj300ENqa2tTYWGhcnJytG7dOvX39ys5OVmBQEB1dXXX+DEAABi7RgzyB1m1apVqa2vV3NyszMxMlZaWKiUlRTU1NaqqqpLNZlN1dbVcLm5BAQAwWqMO8qpVq8J/bmxsvOJ5n88nn88XnakAABhj+KUuAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADCAPdIBg4ODWrt2rd577z29//77evTRRzVz5kytWbNGw8PD8ng82rhxoxwOh1paWtTU1KSkpCSVl5errKzsZnwGAABueRGD/Nvf/lZZWVlasWKFTp48qa9+9avKy8tTRUWFSkpKtGnTJvn9fpWWlqqhoUF+v18pKSlatGiR5s+fr7S0tJvxOQAAuKVFvGW9YMECrVixQpJ06tQpTZw4UR0dHSouLpYkFRUVqb29XZ2dncrOzpbL5ZLT6VReXp4CgUBspwcAIEFEvEL+lyVLlujdd9/Vtm3btHz5cjkcDklSRkaGLMtSMBiU2+0OH+92u2VZVvQnBgAgAY06yHv27NGxY8f07W9/W6FQKLx++Z8vd7X1y6Wnp8puTx7tCPgPHo8r3iOMCexz7LHHsRetPT4WlbMkrhvZ54hBPnr0qDIyMnT77bfrnnvu0fDwsMaNG6ehoSE5nU51d3fL6/XK6/UqGAyGX9fT06Pc3NwRz93bO3Ddg0OyrDPxHmFMYJ9jjz2OPfb45oi0zyMFO+J3yEeOHNGOHTskScFgUAMDAyooKFBra6skqa2tTYWFhcrJyVFXV5f6+/t17tw5BQIB5efnX8vnAABgzIp4hbxkyRJ997vfVUVFhYaGhrR+/XplZWWptrZWzc3NyszMVGlpqVJSUlRTU6OqqirZbDZVV1fL5eI2FAAAoxExyE6nU88999wV642NjVes+Xw++Xy+6EwGAMAYwi91AQBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIAB7KM56JlnntEf/vAHXbx4UV//+teVnZ2tNWvWaHh4WB6PRxs3bpTD4VBLS4uampqUlJSk8vJylZWVxXp+AAASQsQgHz58WH/729/U3Nys3t5eLVy4UHPmzFFFRYVKSkq0adMm+f1+lZaWqqGhQX6/XykpKVq0aJHmz5+vtLS0m/E5AAC4pUW8Zf3JT35SmzdvliRNmDBBg4OD6ujoUHFxsSSpqKhI7e3t6uzsVHZ2tlwul5xOp/Ly8hQIBGI7PQAACSJikJOTk5WamipJ8vv9+uxnP6vBwUE5HA5JUkZGhizLUjAYlNvtDr/O7XbLsqwYjQ0AQGIZ1XfIknTw4EH5/X7t2LFDn//858ProVDoA4+/2vrl0tNTZbcnj3YE/AePxxXvEcYE9jn22OPYi9YeH4vKWRLXjezzqIL8u9/9Ttu2bdP27dvlcrmUmpqqoaEhOZ1OdXd3y+v1yuv1KhgMhl/T09Oj3NzcEc/b2ztw3YNDsqwz8R5hTGCfY489jj32+OaItM8jBTviLeszZ87omWee0QsvvBD+D7QKCgrU2toqSWpra1NhYaFycnLU1dWl/v5+nTt3ToFAQPn5+dfyOQAAGLMiXiHv379fvb29+sY3vhFee/rpp7Vu3To1NzcrMzNTpaWlSklJUU1NjaqqqmSz2VRdXS2Xi9tQAACMRsQgL168WIsXL75ivbGx8Yo1n88nn88XnckAABhD+KUuAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADAAQQYAwAAEGQAAAxBkAAAMQJABADDAqIL817/+VfPmzdPPfvYzSdKpU6dUWVmpiooKrV69WufPn5cktbS06OGHH1ZZWZn27t0bu6kBAEgwEYM8MDCgJ598UnPmzAmvbdmyRRUVFdq9e7fuuusu+f1+DQwMqKGhQTt37tSuXbvU1NSkvr6+mA4PAECiiBhkh8OhF198UV6vN7zW0dGh4uJiSVJRUZHa29vV2dmp7OxsuVwuOZ1O5eXlKRAIxG5yAAASiD3iAXa77PZ/P2xwcFAOh0OSlJGRIcuyFAwG5Xa7w8e43W5ZlhXlcQEASEwRgxxJKBS6pvXLpaenym5PvtERxiyPxxXvEcYE9jn22OPYi9YeH4vKWRLXjezzdQU5NTVVQ0NDcjqd6u7ultfrldfrVTAYDB/T09Oj3NzcEc/T2ztwPW+P/2NZZ+I9wpjAPsceexx77PHNEWmfRwr2df21p4KCArW2tkqS2traVFhYqJycHHV1dam/v1/nzp1TIBBQfn7+9ZweAIAxJ+IV8tGjR7VhwwadPHlSdrtdra2tevbZZ7V27Vo1NzcrMzNTpaWlSklJUU1NjaqqqmSz2VRdXS2Xi9tQAACMRsQgZ2VladeuXVesNzY2XrHm8/nk8/miMxkAAGMIv9QFAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAYgyAAAGIAgAwBgAIIMAIABCDIAAAawR/uETz31lDo7O2Wz2VRXV6dZs2ZF+y0AAEg4UQ3yG2+8obffflvNzc06ceKE6urq1NzcHM23AAAgIUX1lnV7e7vmzZsnSbr77rt1+vRpnT17NppvAQBAQopqkIPBoNLT08OP3W63LMuK5lsAAJCQov4d8uVCodCIz3s8rojn2P3Ml6M1Dq5i5/LN8R5hTFjwX43xHiHh1f2wLN4jJDzPg/XxHiFhRfUK2ev1KhgMhh/39PTI4/FE8y0AAEhIUQ3yZz7zGbW2tkqS/vznP8vr9Wr8+PHRfAsAABJSVG9Z5+Xl6eMf/7iWLFkim82m733ve9E8PQAACcsWivRFLwAAiDl+qQsAAAMQZAAADECQAQAwAEG+Dvv27Yv3CAmrr69Pp0+fjvcYCamnp0d79uwJP/7pT3+qnp6eOE4EXL+LFy/Ge4Soi+kPgySCrq4uvfjii+rr65MkXbhwQcFgUAsXLozzZInl5Zdf1pYtW+RyuRQKhTQ4OKjHH39cDz74YLxHSxi1tbUqK/v/H86YPn261q5dqx07dsRxqsRw//33y2azfeBzNptNBw8evMkTJa7Dhw/rqaee0vnz53XgwAH96Ec/Un5+vgoLC+M92g0jyBH84Ac/0De/+U09++yzqq+v129+8xvl5ubGe6yE09TUpFdffVVpaWmSpH/+859avnw5QY6ioaEhLViwIPy4qKiIGEfJr371K4VCIb3wwguaOXOmPv3pT+vSpUs6fPiw3n777XiPl1C2bt2qpqYmPfbYY5KkZcuW6dFHHyXIY4HT6dTs2bPlcDiUlZWlrKwsVVVVqaioKN6jJZSPfOQjmjBhQvhxenq6Jk+eHMeJEk9mZqY2bNigvLy8cCwyMzPjPVZCSE1NlSQFAgE9/vjj4fUvfvGLWr58ebzGSkh2u13p6enhOxIZGRlXvTtxqyHIEXzoQx/Sa6+9pjvuuEObNm3SnXfeqVOnTsV7rISxYcMG2Ww2OZ1OlZaW6hOf+IRsNpv++Mc/asqUKfEeL6Fs2LBB+/bt0+9//3slJycrJydHDzzwQLzHSigOh0NPP/207r33XiUlJamrq0vDw8PxHiuh3HHHHdq8ebN6e3u1f/9+HTx4UNOnT4/3WFHBD4NEcPbsWQWDQd12223auXOn+vr69NBDDyk7OzveoyWESP+BHN/V41Zy9uxZtbS06MSJEwqFQpoyZYpKS0vlckX+H+lgdC5duqRf/vKXevPNN5WSkqKcnByVlJQoOTk53qPdMIIMAIAB+GtPAAAYgCADAGAAggwAgAEIMgAABiDIAAAY4H8BVhZtr1sqt70AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgwMaNPUfvt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)        \n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size * 2)\n",
        "        \n",
        "        #self.softAct = nn.Softmax(dim=1)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_dim), torch.zeros(1, 1, self.hidden_dim))\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        step_logger.add_info(sentence,\"forward sentence\")\n",
        "        \n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        step_logger.add_info(embeds,\"forward embeds\")\n",
        "        \n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        step_logger.add_info(lstm_out,\"forward lstm_out\")\n",
        "                \n",
        "        last_layer =  lstm_out[-1]\n",
        "        step_logger.add_info(last_layer,\"forward last_layer\")\n",
        "\n",
        "        tag_space =  self.hidden2tag(last_layer)\n",
        "        step_logger.add_info(tag_space,\"forward tag_space\")\n",
        "\n",
        "        tag_view = tag_space.view(2, -1)\n",
        "        step_logger.add_info(tag_view,\"forward tag_view\")        \n",
        "        \n",
        "        #tag_scores = F.log_softmax(tag_view)\n",
        "        #step_logger.add_info(tag_scores,\"forward tag_scores\")\n",
        "        \n",
        "        return tag_view"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOG3tcxigJuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "def eval(model_,   X_, y_,full_match):\n",
        "     \n",
        "     correct = 0\n",
        "     #model_.eval()\n",
        "     \n",
        "     for index in range(len(X_)):\n",
        "         test_input = X_[index]\n",
        "         test_output = y_[index]\n",
        "         \n",
        "         actuals,expecteds,score = infer( model_, test_input,test_output,full_match)\n",
        "         correct += score\n",
        "         \n",
        "     #print(\"  correct\",correct,\"len(X_) \",len(X_))       \n",
        "     accuracy = 0                   \n",
        "     if full_match : \n",
        "       accuracy = (correct * 100 ) /len(X_)\n",
        "     else:  \n",
        "       accuracy = ( correct * 100 ) / ( len(X_) * 2) #we are counting partial match as partial success\n",
        "     return accuracy\n",
        "\n",
        "  \n",
        "\n",
        "def infer(model_,test_input,test_output,full_match):\n",
        "  \n",
        "  name_ohe = prepare_sequence(test_input)\n",
        "  \n",
        "  t = torch.tensor(name_ohe, dtype = torch.long)\n",
        "\n",
        "  tag_scores = model_(t)  \n",
        "  val, indices = tag_scores.topk(1)\n",
        "\n",
        "  actuals = indices.squeeze().numpy()\n",
        "  expecteds = prepare_sequence(test_output).flatten().astype(int)\n",
        "  #print(\"actuals \",actuals,\" expecteds \",expecteds)\n",
        "  score =0\n",
        "  if full_match :\n",
        "    score = int( actuals[0] == expecteds[0] and actuals[1] == expecteds[1])\n",
        "  else :\n",
        "    score = int(actuals[0] == expecteds[0]) + int(actuals[1] == expecteds[1])\n",
        "\n",
        "  return actuals,expecteds,score\n",
        "\n",
        "def train_epoch(shuffled,optimizer):\n",
        "  last_loss = 0\n",
        "  for sentence, tags in shuffled:\n",
        "    # Step 1. Remember that Pytorch accumulates gradients.\n",
        "    # We need to clear them out before each instance\n",
        "    model.zero_grad()\n",
        "    #print(\"pass\")\n",
        "    # Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "    # Tensors of word indices.\n",
        "    #print(\"tags\",tags)\n",
        "    \n",
        "    sentence_in = torch.tensor(prepare_sequence(sentence), dtype=torch.long) \n",
        "    targets = torch.tensor(prepare_sequence(tags), dtype=torch.long )  \n",
        "            \n",
        "    step_logger.add_info(sentence_in,\"train sentence_in\")\n",
        "\n",
        "    # Step 3. Run our forward pass.\n",
        "    tag_scores = model(sentence_in)\n",
        "\n",
        "    # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "    #  calling optimizer.step()\n",
        "    \n",
        "    step_logger.add_info(tag_scores.squeeze(),\"train tag_scores\")\n",
        "    step_logger.add_info(targets,\"train targets\")\n",
        "    \n",
        "    loss = loss_function(tag_scores.squeeze(), targets.squeeze())\n",
        "    loss.backward()\n",
        "    optimizer.step()  \n",
        "    last_loss = loss\n",
        "  return last_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry9MJ_JAgNgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definition of model\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, 5, 5)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "step_logger =  StepLogger(2)\n",
        "training_data = zip(X_train,y_train)\n",
        "tranlist = list(training_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QqsCS9XgSRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "916fb818-7d51-4f79-86f0-487425f2b233"
      },
      "source": [
        "import timeit\n",
        "\n",
        "\n",
        "for epoch in range(21): \n",
        "    start_time = timeit.default_timer() # again, normally you would NOT do 300 epochs, it is toy data\n",
        "    #print(\"\\n\\n\",\"epoch\",epoch)\n",
        "    if epoch % 2 == 1:\n",
        "      #tests = [ gen_data_tuple() for _ in range(200)]\n",
        "      with torch.no_grad() :\n",
        "        #clear_output(wait = True)\n",
        "        print(\"--------------------\")\n",
        "        print(epoch ,\"   Epoch Full sequence \", round(eval(model,  X_test, y_test,True),2) )\n",
        "        print(epoch ,\"   Epoch Partial       \" ,round(eval(model,  X_test, y_test,False),2) )\n",
        "\n",
        "    \n",
        "    shuffled = tranlist #random.sample(tranlist, len(tranlist))  \n",
        "     \n",
        "    #model.train()\n",
        "    #with torch.grad():\n",
        "    epoch_loss = train_epoch(shuffled,optimizer)    \n",
        "    elapsed = timeit.default_timer() - start_time    \n",
        "    #print(epoch,\" elapsed \",elapsed,\" epoch_loss \",epoch_loss)\n",
        "    \n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "1    Epoch Full sequence  60.0\n",
            "1    Epoch Partial        78.5\n",
            "--------------------\n",
            "3    Epoch Full sequence  78.0\n",
            "3    Epoch Partial        88.75\n",
            "--------------------\n",
            "5    Epoch Full sequence  85.0\n",
            "5    Epoch Partial        92.25\n",
            "--------------------\n",
            "7    Epoch Full sequence  91.5\n",
            "7    Epoch Partial        95.75\n",
            "--------------------\n",
            "9    Epoch Full sequence  92.0\n",
            "9    Epoch Partial        96.0\n",
            "--------------------\n",
            "11    Epoch Full sequence  93.5\n",
            "11    Epoch Partial        96.5\n",
            "--------------------\n",
            "13    Epoch Full sequence  94.0\n",
            "13    Epoch Partial        97.0\n",
            "--------------------\n",
            "15    Epoch Full sequence  87.0\n",
            "15    Epoch Partial        93.0\n",
            "--------------------\n",
            "17    Epoch Full sequence  96.5\n",
            "17    Epoch Partial        98.0\n",
            "--------------------\n",
            "19    Epoch Full sequence  97.0\n",
            "19    Epoch Partial        98.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKx6MpSgUgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "e56fb1db-9df6-4808-e2ec-475d51e57668"
      },
      "source": [
        "#check intermediate object shapes\n",
        "step_logger.get_default_summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train sentence_in\n",
            "[6, 1]\n",
            "forward sentence\n",
            "[6, 1]\n",
            "forward embeds\n",
            "[6, 1, 6]\n",
            "forward lstm_out\n",
            "[6, 1, 6]\n",
            "forward last_layer\n",
            "[1, 6]\n",
            "forward tag_space\n",
            "[1, 10]\n",
            "forward tag_view\n",
            "[2, 5]\n",
            "train tag_scores\n",
            "[2, 5]\n",
            "train targets\n",
            "[2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_GtZ4zmibpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8112da5e-362d-42ce-9901-036dfb88b0b6"
      },
      "source": [
        "#check intermediate object samples\n",
        "step_logger.get_default_summary(True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train sentence_in\n",
            "[6, 1]\n",
            "tensor([[4],\n",
            "        [2],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [1]])\n",
            "forward sentence\n",
            "[6, 1]\n",
            "tensor([[4],\n",
            "        [2],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [1]])\n",
            "forward embeds\n",
            "[6, 1, 6]\n",
            "tensor([[[-2.1984,  0.2861, -0.2010, -2.5349, -1.3196,  1.6485]],\n",
            "\n",
            "        [[ 0.2693, -0.4886, -0.5606, -0.6555,  0.7262,  0.6789]],\n",
            "\n",
            "        [[ 1.0757, -0.5536, -3.2686,  0.4750, -2.1142, -1.5002]],\n",
            "\n",
            "        [[ 0.2693, -0.4886, -0.5606, -0.6555,  0.7262,  0.6789]],\n",
            "\n",
            "        [[ 0.2693, -0.4886, -0.5606, -0.6555,  0.7262,  0.6789]],\n",
            "\n",
            "        [[ 1.0757, -0.5536, -3.2686,  0.4750, -2.1142, -1.5002]]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "forward lstm_out\n",
            "[6, 1, 6]\n",
            "tensor([[[-0.0047, -0.0221,  0.1305, -0.2407,  0.1358, -0.1925]],\n",
            "\n",
            "        [[ 0.0115,  0.0516,  0.1428, -0.1114,  0.1675, -0.1921]],\n",
            "\n",
            "        [[ 0.3817, -0.0492, -0.0840, -0.1207, -0.0196, -0.1366]],\n",
            "\n",
            "        [[ 0.1550,  0.0110, -0.0656, -0.0381,  0.0800, -0.1663]],\n",
            "\n",
            "        [[ 0.1066,  0.0749, -0.0184,  0.0283,  0.1128, -0.1988]],\n",
            "\n",
            "        [[ 0.4220, -0.0455, -0.1612, -0.0337, -0.0916, -0.1562]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "forward last_layer\n",
            "[1, 6]\n",
            "tensor([[ 0.4220, -0.0455, -0.1612, -0.0337, -0.0916, -0.1562]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "forward tag_space\n",
            "[1, 10]\n",
            "tensor([[-0.1443, -0.0482, -0.2865,  0.3158, -0.2439, -0.0501, -0.5446, -0.0437,\n",
            "         -0.1839, -0.3643]], grad_fn=<AddmmBackward>)\n",
            "forward tag_view\n",
            "[2, 5]\n",
            "tensor([[-0.1443, -0.0482, -0.2865,  0.3158, -0.2439],\n",
            "        [-0.0501, -0.5446, -0.0437, -0.1839, -0.3643]], grad_fn=<ViewBackward>)\n",
            "train tag_scores\n",
            "[2, 5]\n",
            "tensor([[-0.1443, -0.0482, -0.2865,  0.3158, -0.2439],\n",
            "        [-0.0501, -0.5446, -0.0437, -0.1839, -0.3643]],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "train targets\n",
            "[2, 1]\n",
            "tensor([[2],\n",
            "        [1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aUfNKididYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "c3f18e0e-2908-43e1-f643-079274e4fbcf"
      },
      "source": [
        "#test some samples\n",
        "for index_ in range(10):\n",
        "  print(X_test[index_],y_test[index_])\n",
        "  a,b,c = infer( model, X_test[index_],y_test[index_],False)\n",
        "  print( a,b,c)\n",
        "  a,b,c = infer( model, X_test[index_],y_test[index_],True)\n",
        "  print( a,b,c)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['d', 'c', 'd', 'a', 'c', 'c'] ['c', 'd']\n",
            "[2 3] [2 3] 2\n",
            "[2 3] [2 3] 1\n",
            "['c', 'a', 'd', 'a', 'c', 'a'] ['a', 'c']\n",
            "[0 2] [0 2] 2\n",
            "[0 2] [0 2] 1\n",
            "['d', 'b', 'b', 'd', 'a', 'b'] ['b', 'd']\n",
            "[1 3] [1 3] 2\n",
            "[1 3] [1 3] 1\n",
            "['a', 'e', 'e', 'b', 'e', 'b'] ['e', 'b']\n",
            "[4 1] [4 1] 2\n",
            "[4 1] [4 1] 1\n",
            "['a', 'a', 'a', 'e', 'e', 'a'] ['a', 'e']\n",
            "[0 4] [0 4] 2\n",
            "[0 4] [0 4] 1\n",
            "['d', 'd', 'd', 'd', 'b', 'b'] ['d', 'b']\n",
            "[3 1] [3 1] 2\n",
            "[3 1] [3 1] 1\n",
            "['c', 'a', 'b', 'b', 'c', 'b'] ['b', 'c']\n",
            "[1 2] [1 2] 2\n",
            "[1 2] [1 2] 1\n",
            "['e', 'a', 'a', 'a', 'e', 'a'] ['a', 'e']\n",
            "[0 4] [0 4] 2\n",
            "[0 4] [0 4] 1\n",
            "['e', 'e', 'e', 'c', 'b', 'c'] ['e', 'c']\n",
            "[4 2] [4 2] 2\n",
            "[4 2] [4 2] 1\n",
            "['e', 'd', 'c', 'e', 'e', 'c'] ['e', 'c']\n",
            "[4 2] [4 2] 2\n",
            "[4 2] [4 2] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VF3Yzj-k23a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}